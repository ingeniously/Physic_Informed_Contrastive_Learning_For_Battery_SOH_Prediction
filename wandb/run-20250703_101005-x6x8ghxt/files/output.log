Loading original dataset...
Original dataset loaded: 683 training batches
Loading augmented dataset...
Augmented dataset loaded: 2065 training batches
Initializing PINN model...
2025-07-03 10:10 - function:_save_args - INFO - Args:
2025-07-03 10:10 - function:_save_args - CRITICAL - 	csv_file:/home/choi/PICL/data_processed/preprocessed_battery_health_dataset_all_points.csv
2025-07-03 10:10 - function:_save_args - CRITICAL - 	csv_file_augmented:/home/choi/PICL/data_augmentation/battery_phys_augmented.csv
2025-07-03 10:10 - function:_save_args - CRITICAL - 	batch_size:128
2025-07-03 10:10 - function:_save_args - CRITICAL - 	normalization_method:z-score
2025-07-03 10:10 - function:_save_args - CRITICAL - 	epochs:50
2025-07-03 10:10 - function:_save_args - CRITICAL - 	early_stop:30
2025-07-03 10:10 - function:_save_args - CRITICAL - 	lr:0.0005
2025-07-03 10:10 - function:_save_args - CRITICAL - 	lr_F:0.0005
2025-07-03 10:10 - function:_save_args - CRITICAL - 	save_folder:result_small_sample_05_06_07_18
2025-07-03 10:10 - function:_save_args - CRITICAL - 	alpha:1.0
2025-07-03 10:10 - function:_save_args - CRITICAL - 	beta:0.5
2025-07-03 10:10 - function:_save_args - CRITICAL - 	contrastive_weight:0.1
2025-07-03 10:10 - function:_save_args - CRITICAL - 	pinn_weight:1.0
2025-07-03 10:10 - function:_save_args - CRITICAL - 	temperature:0.1
2025-07-03 10:10 - function:_save_args - CRITICAL - 	log_dir:training_log.txt
2025-07-03 10:10 - function:_save_args - CRITICAL - 	F_layers_num:4
2025-07-03 10:10 - function:_save_args - CRITICAL - 	F_hidden_dim:128
2025-07-03 10:10 - function:_save_args - CRITICAL - 	warmup_lr:0.0001
2025-07-03 10:10 - function:_save_args - CRITICAL - 	final_lr:1e-05
2025-07-03 10:10 - function:_save_args - CRITICAL - 	warmup_epochs:50
2025-07-03 10:10 - function:_save_args - CRITICAL - 	momentum:0.999
2025-07-03 10:10 - function:_save_args - CRITICAL - 	projection_dim:128
2025-07-03 10:10 - function:_save_args - CRITICAL - 	queue_size:4096
2025-07-03 10:10 - function:_save_args - CRITICAL - 	seed:42
2025-07-03 10:10 - function:_save_args - CRITICAL - 	wandb_project:battery-picle
2025-07-03 10:10 - function:_save_args - CRITICAL - 	wandb_entity:None
2025-07-03 10:10 - function:_save_args - CRITICAL - 	wandb_run_name:None
Could not create model visualization for wandb
Setting up contrastive learning wrapper...
PINN model has 41986 trainable parameters
Full contrastive wrapper has 158594 trainable parameters
Starting training...
[Epoch 1/50] Current temperature: 0.2250
[Epoch 1] Total loss: 6294.8766 | PINN loss: 6294.7348 | Contrastive loss: 4.7281 | PDE loss: 0.0383 | Physics loss: 1.8331
[Validation] Epoch 1: MSE = 5948.195801
New best model saved at epoch 1 with validation MSE: 5948.195801
[Test] MSE: 5765.43359375, MAE: 75.605827, MAPE: 13.182614, RMSE: 75.930450, RÂ²: -116.2733
Enhanced prediction scatter plot saved to result_small_sample_05_06_07_18/prediction_scatter_epoch_1.png
[Epoch 2/50] Current temperature: 0.2229
[Epoch 2] Total loss: 5831.5271 | PINN loss: 5831.3865 | Contrastive loss: 4.6873 | PDE loss: 0.0078 | Physics loss: 1.1807
[Epoch 3/50] Current temperature: 0.2207
[Epoch 3] Total loss: 5565.6604 | PINN loss: 5565.5201 | Contrastive loss: 4.6775 | PDE loss: 0.0050 | Physics loss: 1.1290
[Epoch 4/50] Current temperature: 0.2186
Traceback (most recent call last):
  File "main.py", line 856, in <module>
    main()
  File "main.py", line 850, in main
    train_contrastive_pinn(wrapper, orig_loader, aug_loader, args)
  File "main.py", line 190, in train_contrastive_pinn
    total_loss, pinn_loss, contrastive_loss, pde_loss, physics_loss = wrapper(x1, x2, y1, y2)
  File "/home/choi/anaconda3/envs/picl/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/choi/PICL/contrastive_Learning/contrastive.py", line 365, in forward
    sup_loss = self.supervised_contrastive_loss(q1_norm, q2_norm, y1, y2)
  File "/home/choi/PICL/contrastive_Learning/contrastive.py", line 215, in supervised_contrastive_loss
    positive_indices = torch.nonzero(similarity_mask[i] & ~self_mask[i]).flatten()
KeyboardInterrupt
